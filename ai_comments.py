import json
import os
import time
import random
from datetime import datetime
from google import genai
from google.genai import types

# ================= ğŸ”§ æ¨¡å‹ä¸ç­–ç•¥é…ç½® =================
MODEL_REGISTRY = {
    "smart": "gemini-3-flash-preview",       # èªæ˜/ä¸“ä¸šè§’è‰²ç”¨
    "cheap": "gemini-2.5-flash", # æ™®é€š/åƒç“œè§’è‰²ç”¨
}

DEFAULT_MODEL = "cheap"

# ğŸŒŸ æ™ºèƒ½åˆ†ç»„å…³é”®è¯ï¼šåŒ…å«è¿™äº›è¯çš„è§’è‰²ä¼šåˆ†é…ç»™ "smart" æ¨¡å‹
HIGH_INTEL_KEYWORDS = [
    "åŒ»ç”Ÿ", "åˆ†æå¸ˆ", "åšä¸»", "è€å¸ˆ", "åˆ›ä¸šè€…", "æåé—¨", 
    "å¤§å‚", "å¾‹å¸ˆ", "å…¬åŠ¡å‘˜", "è€å¹²éƒ¨", "é¦–å¯Œ", 
    "é©¬æ–¯å…‹", "é©¬äº‘", "è€æ¿", "å•†å®¶", "å­¦éœ¸", "å¤±ä¸šäººå‘˜"
]

# ================= ğŸ­ 40+ ç§èŒä¸šä¸äººè®¾å®šä¹‰ (å·²æ‰©å±•) =================
PERSONAS = [
    # --- æ–°å¢è§’è‰² ---
    "è·¨å¢ƒç”µå•†å•†å®¶ (ç„¦è™‘/å…³æ³¨æ±‡ç‡ä¸å…³ç¨)", 
    "ä¸–ç•Œé¦–å¯Œ (å‡¡å°”èµ›/å®è§‚è§†è§’)", 
    "ä¸Šå¸‚å…¬å¸è€æ¿ (ç”»å¤§é¥¼/å±æœºæ„Ÿ)", 
    "å›½å†…ç”µå•†å•†å®¶ (å·ç‹/æŠ±æ€¨é€€è´§ç‡)", 
    "åŸƒéš†é©¬æ–¯å…‹ (ç¡¬æ ¸/ç¬¬ä¸€æ€§åŸç†/è‹±è¯­å£ç™–)", 
    "é©¬äº‘ (é€€éš/å“²ç†/å¤ªæ)", 
    "å¤±ä¸šäººå‘˜ (è¿·èŒ«/è‡ªå˜²/å¯»æ‰¾æœºä¼š)", 
    "é«˜ä¸­ç”Ÿ (åˆ·é¢˜ç´¯/åæ§½æ•™è‚²/ç©æ¢—)", 
    "æ•°å­¦è€å¸ˆ (é€»è¾‘ä¸¥å¯†/å–œæ¬¢æ¨ç†)", 
    "è¯­æ–‡è€å¸ˆ (æ„Ÿæ€§/å¼•ç»æ®å…¸)", 
    "æåé—¨çš„äºº (å®¹æ˜“æ‰¾ç‚¹æ·å¾„çªç ´å£å’Œæœ‰å¯¹ä¿¡æ¯æ•é”çš„æ´å¯Ÿèƒ½åŠ›/èƒ½æ³¨æ„åˆ°å¹³å¸¸äººæ³¨æ„ä¸åˆ°çš„ä¿¡æ¯å·®)", 
    
    # --- åŸæœ‰è§’è‰² ---
    "å‡ºç§Ÿè½¦å¸æœº (è€ç»ƒ/æ„¤ä¸–å«‰ä¿—)", "å¤§ä¸€æ–°ç”Ÿ (æ¸…æ¾ˆ/å……æ»¡å¸Œæœ›)", "èœå¸‚åœºå¤§å¦ˆ (åŠ¡å®/å…³å¿ƒç‰©ä»·)", 
    "äº’è”ç½‘å¤§å‚P7 (ç„¦è™‘/æ»¡å£é»‘è¯)", "é€€ä¼‘è€å¹²éƒ¨ (ä¸¥è‚ƒ/å®å¤§å™äº‹)", "ä¸‰ç”²åŒ»é™¢åŒ»ç”Ÿ (å†·é™/ç–²æƒ«)", 
    "å…¨èŒå¦ˆå¦ˆ (ç»†è…»/æ‹…å¿§)", "åŸä¸­æ‘æˆ¿ä¸œ (æ‚ é—²/å‡¡å°”èµ›)", "å°å­¦ç­ä¸»ä»» (æ“å¿ƒ/ä¸¥å‰)", 
    "é‡‘èåˆ†æå¸ˆ (ç†æ€§/æ•°æ®æµ)", "ä¸çŸ¥åæ‘‡æ»šä¹æ‰‹ (å›é€†/è®½åˆº)", "å°å–éƒ¨è€æ¿ (å…«å¦/é€šé€)", 
    "å¤§æ¨¡å‹åˆ›ä¸šè€… (ç‹‚çƒ­/æ¿€è¿›)", "å¤–å–å°å“¥ (åŒ†å¿™/æœ€æ‡‚äººé—´)", "æµ·å½’ç•™å­¦ç”Ÿ (å¤¹æ‚è‹±æ–‡/æ¯”è¾ƒè§†è§’)", 
    "å·¥åœ°åŒ…å·¥å¤´ (è±ªçˆ½/ç›´æ¥)", "è€ƒç ”å…š (ç´§ç»·/è¿·èŒ«)", "èµ„æ·±è‚¡æ°‘ (å¤§èµ·å¤§è½/ç”šè‡³æœ‰ç‚¹ç–¯)", 
    "00åæ•´é¡¿èŒåœº (ç›´æ¥/æ— æ‰€è°“)", "å¤é£æ±‰æœçˆ±å¥½è€… (æ–‡è‰º/æ„Ÿæ€§)", "ç§‘æŠ€åšä¸» (ä¸“ä¸š/æŒ‘åˆº)", 
    "å®¶åº­ä¸»å¦‡ (ç²¾æ‰“ç»†ç®—)", "ä¸­å­¦ç‰©ç†è€å¸ˆ (ä¸¥è°¨/è¾ƒçœŸ)", "å›½ä¼å‘˜å·¥ (ç¨³é‡/æ‰“å¤ªæ)", 
    "å¥èº«æ•™ç»ƒ (æ­£èƒ½é‡/é¸¡è¡€)", "äºŒæ¬¡å…ƒå®…ç”· (ç©æ¢—/å¹½é»˜)", "ç¾å®¹é™¢è€æ¿å¨˜ (åœ†æ»‘/é¢œæ§)", 
    "åŸºå±‚å…¬åŠ¡å‘˜ (è°¨æ…/æ­£èƒ½é‡)", "æš´å‘æˆ· (ç‚«è€€/ç²—ä¿—)", "AIæ‚²è§‚ä¸»ä¹‰è€… (ææƒ§/æœ«æ—¥è®º)"
]

# ================= ğŸ“‚ æ–‡ä»¶é…ç½® =================
FILES_CONFIG = {
    "finance": { "in": "data_finance.json", "out": "comments_finance.json", "name": "è´¢ç»/å¸‚åœº" },
    "global": { "in": "data_global.json",  "out": "comments_global.json",  "name": "å›½é™…/å®è§‚" },
    "tech": { "in": "data_tech.json",    "out": "comments_tech.json",    "name": "ç§‘æŠ€/AI" },
    "general": { "in": "data_general.json", "out": "comments_general.json", "name": "å¨±ä¹/åƒç“œ" }
}

KEY_VARS = ["KEY_1", "KEY_2", "KEY_3", "KEY_4", "KEY_5", "KEY_6", "KEY_7", "KEY_8"]

def get_random_client():
    valid_keys = [os.environ.get(k) for k in KEY_VARS if os.environ.get(k)]
    if not valid_keys:
        print("âŒ é”™è¯¯ï¼šæœªæ£€æµ‹åˆ° API Key")
        return None
    return genai.Client(api_key=random.choice(valid_keys), http_options={'api_version': 'v1alpha'})

def load_news_summary(filepath):
    if not os.path.exists(filepath): return ""
    with open(filepath, "r", encoding="utf-8") as f: data = json.load(f)
    summary = []
    count = 0
    for platform in data:
        items = platform.get('items', [])
        for item in items:
            if count >= 15: break
            summary.append(f"- {item.get('title')}")
            count += 1
    return "\n".join(summary)

def assign_model_to_personas():
    batches = {}
    for persona in PERSONAS:
        assigned_alias = DEFAULT_MODEL
        for kw in HIGH_INTEL_KEYWORDS:
            if kw in persona:
                assigned_alias = "smart"
                break
        real_model_name = MODEL_REGISTRY.get(assigned_alias, MODEL_REGISTRY[DEFAULT_MODEL])
        if real_model_name not in batches: batches[real_model_name] = []
        batches[real_model_name].append(persona)
    return batches

def process_batch(client, model_name, personas_list, news_text, category_name):
    if not personas_list: return []
    print(f"   âš¡ [{model_name}] ç”Ÿæˆ {len(personas_list)} ä¸ªè§’è‰²è¯„è®º...")
    
    # ğŸ”¥ğŸ”¥ğŸ”¥ æ ¸å¿ƒ Prompt ä¿®æ”¹ï¼šå¢åŠ éšæœºæ€§å’Œé•¿çŸ­ä¸ä¸€çš„è¦æ±‚ ğŸ”¥ğŸ”¥ğŸ”¥
    prompt = f"""
    ä½ æ˜¯ä¸€ä¸ªå…¨ç½‘èˆ†æƒ…æ¨¡æ‹Ÿå™¨ã€‚è¯·é˜…è¯»ä»Šå¤©çš„ã€{category_name}ã€‘æ¿å—çƒ­æœæ–°é—»ï¼š
    {news_text}

    ä»»åŠ¡ï¼šæ¨¡æ‹Ÿä»¥ä¸‹åˆ—è¡¨ä¸­çš„ä¸åŒèŒä¸š/äººè®¾çš„çœŸå®ç½‘å‹ï¼Œé’ˆå¯¹ä¸Šè¿°æ–°é—»å‘è¡¨è¯„è®ºã€‚
    
    ã€å¾…æ¨¡æ‹Ÿè§’è‰²åˆ—è¡¨ã€‘ï¼š
    {', '.join(personas_list)}

    ã€âš ï¸ ä¸¥æ ¼çš„é£æ ¼è¦æ±‚ã€‘ï¼š
    1. **å®Œå…¨ä»£å…¥è§’è‰²**ï¼šå¦‚æœæ˜¯é©¬æ–¯å…‹å°±è¦åƒé©¬æ–¯å…‹ï¼ˆæç¬¬ä¸€æ€§åŸç†/ç«æ˜Ÿ/Dogeï¼‰ï¼Œå¦‚æœæ˜¯å­¦ç”Ÿå°±è¦åƒå­¦ç”Ÿï¼ˆä½œä¸š/è€ƒè¯•ï¼‰ã€‚
    2. **å­—æ•°éšæœºåŒ–**ï¼š
       - å¤§éƒ¨åˆ†è¯„è®ºä¿æŒç®€çŸ­ï¼ˆ30-60å­—ï¼‰ã€‚
       - **å¿…é¡»æœ‰ 3-5 ä¸ªè§’è‰²å‘è¡¨â€œé•¿ç¯‡å¤§è®ºâ€**ï¼ˆ100-150å­—ï¼‰ï¼Œè¿›è¡Œæ·±åº¦åˆ†ææˆ–æƒ…ç»ªå‘æ³„ã€‚
       - æå°‘æ•°è§’è‰²å¯ä»¥åªå‘å‡ ä¸ªå­—ï¼ˆå¦‚â€œç‰›é€¼â€ã€â€œç”šè‡³æœ‰ç‚¹æƒ³ç¬‘â€ï¼‰ã€‚
    3. **Emoji éšæœºåŒ–**ï¼š
       - æœ‰äº›äººï¼ˆå¦‚00å/é”€å”®ï¼‰å–œæ¬¢ç‹‚ç”¨ Emojiã€‚
       - æœ‰äº›äººï¼ˆå¦‚è€å¸ˆ/å¤§ä½¬/è€å¹²éƒ¨ï¼‰éå¸¸ä¸¥è‚ƒï¼Œ**ç»å¯¹ä¸ç”¨** Emojiã€‚
    4. **æ‹’ç»æ­»æ¿**ï¼šä¸è¦æ¯ä¸ªäººçš„æ ¼å¼éƒ½ä¸€æ ·ï¼Œè¦åƒçœŸå®çš„è¯„è®ºåŒºä¸€æ ·æ··ä¹±è€ŒçœŸå®ã€‚

    è¾“å‡º JSON æ•°ç»„æ ¼å¼ï¼š
    [
        {{
            "role": "è§’è‰²å…¨å",
            "name": "æœ‰è¶£çš„ç½‘å",
            "content": "è¯„è®ºå†…å®¹...",
            "emotion": "æƒ…ç»ªæ ‡ç­¾"
        }}
    ]
    """

    try:
        response = client.models.generate_content(
            model=model_name,
            contents=prompt,
            config=types.GenerateContentConfig(response_mime_type="application/json", temperature=0.9) # æ¸©åº¦è°ƒé«˜ï¼Œå¢åŠ éšæœºæ€§
        )
        return json.loads(response.text)
    except Exception as e:
        print(f"   âš ï¸ é”™è¯¯: {e}")
        return []

def generate_comments(category_key, config):
    client = get_random_client()
    if not client: return
    print(f"ğŸ”„ å¤„ç†æ¿å—ï¼š{config['name']}")
    news_text = load_news_summary(config['in'])
    if not news_text: return

    batches = assign_model_to_personas()
    all_comments = []

    for model_name, personas_sublist in batches.items():
        time.sleep(1)
        batch_client = get_random_client() or client
        comments = process_batch(batch_client, model_name, personas_sublist, news_text, config['name'])
        if comments: all_comments.extend(comments)

    random.shuffle(all_comments)
    
    # éšæœºé€‰å– 30 æ¡å·¦å³ï¼Œé¿å…å¤ªå¤š
    final_comments = all_comments[:35] if len(all_comments) > 35 else all_comments

    if final_comments:
        output_data = { "date": datetime.now().strftime("%Y-%m-%d %H:%M"), "category": category_key, "comments": final_comments }
        with open(config['out'], "w", encoding="utf-8") as f: json.dump(output_data, f, ensure_ascii=False, indent=2)
        print(f"âœ… å®Œæˆï¼ç”Ÿæˆ {len(final_comments)} æ¡è¯„è®ºã€‚\n")

if __name__ == "__main__":
    print(f"ğŸ¤– AI æ¨¡æ‹Ÿè¯„è®ºå¯åŠ¨...")
    for key, config in FILES_CONFIG.items():
        generate_comments(key, config)
        time.sleep(2)